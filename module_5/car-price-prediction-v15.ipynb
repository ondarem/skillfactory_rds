{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Проект №5 \"Выбираем авто\" - работа Елены Ондар"},{"metadata":{},"cell_type":"markdown","source":"## 1. Импорт библиотек"},{"metadata":{"papermill":{"duration":0.028027,"end_time":"2020-10-26T12:46:41.334278","exception":false,"start_time":"2020-10-26T12:46:41.306251","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Помним, что по условию соревнования, нам нужно самостоятельно собрать обучающий датасет. В этом ноутбуке мы не будем рассматривать сбор данных. Предположим, что мы уже все собрали и просто подключили свой датасет через \"Add Data\", чтобы приступить к самому ML."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-10-26T12:46:41.400302Z","iopub.status.busy":"2020-10-26T12:46:41.399317Z","iopub.status.idle":"2020-10-26T12:46:42.581426Z","shell.execute_reply":"2020-10-26T12:46:42.580431Z"},"papermill":{"duration":1.219772,"end_time":"2020-10-26T12:46:42.581597","exception":false,"start_time":"2020-10-26T12:46:41.361825","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\nimport re\nfrom datetime import datetime\n\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tqdm.notebook import tqdm\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, BaggingRegressor, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.tree import ExtraTreeRegressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.base import clone\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.model_selection import cross_validate\n\npd.options.mode.chained_assignment = None\npd.set_option('display.max_columns', None)\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-26T12:46:42.646795Z","iopub.status.busy":"2020-10-26T12:46:42.645765Z","iopub.status.idle":"2020-10-26T12:46:42.649793Z","shell.execute_reply":"2020-10-26T12:46:42.650407Z"},"papermill":{"duration":0.040034,"end_time":"2020-10-26T12:46:42.650603","exception":false,"start_time":"2020-10-26T12:46:42.610569","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print('Python       :', sys.version.split('\\n')[0])\nprint('Numpy        :', np.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2020-10-26T12:46:42.716039Z","iopub.status.busy":"2020-10-26T12:46:42.715184Z","iopub.status.idle":"2020-10-26T12:46:47.852433Z","shell.execute_reply":"2020-10-26T12:46:47.851661Z"},"papermill":{"duration":5.172536,"end_time":"2020-10-26T12:46:47.852593","exception":false,"start_time":"2020-10-26T12:46:42.680057","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:47.919419Z","iopub.status.busy":"2020-10-26T12:46:47.918168Z","iopub.status.idle":"2020-10-26T12:46:47.922267Z","shell.execute_reply":"2020-10-26T12:46:47.921365Z"},"papermill":{"duration":0.039842,"end_time":"2020-10-26T12:46:47.922434","exception":false,"start_time":"2020-10-26T12:46:47.882592","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028837,"end_time":"2020-10-26T12:46:47.981435","exception":false,"start_time":"2020-10-26T12:46:47.952598","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Setup"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.05046Z","iopub.status.busy":"2020-10-26T12:46:48.049412Z","iopub.status.idle":"2020-10-26T12:46:48.052578Z","shell.execute_reply":"2020-10-26T12:46:48.051917Z"},"papermill":{"duration":0.039969,"end_time":"2020-10-26T12:46:48.052728","exception":false,"start_time":"2020-10-26T12:46:48.012759","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"VERSION    = 15\nDIR_TRAIN  = '../input/parsingautoru24122020/' # подключим к ноутбуку внешний датасет\nDIR_TEST   = '../input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.20   # 20%\n\n# CATBOOST\nITERATIONS = 5000\nLR         = 0.1","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030254,"end_time":"2020-10-26T12:46:48.112586","exception":false,"start_time":"2020-10-26T12:46:48.082332","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:46:48.179769Z","iopub.status.busy":"2020-10-26T12:46:48.178918Z","iopub.status.idle":"2020-10-26T12:46:48.924574Z","shell.execute_reply":"2020-10-26T12:46:48.925184Z"},"papermill":{"duration":0.783211,"end_time":"2020-10-26T12:46:48.925418","exception":false,"start_time":"2020-10-26T12:46:48.142207","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!ls '../input'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA для тестовой выборки\nТак как в этом проекте у нас нет выборки для обучения, а есть только тестовая выборка, необходимо: \n* Изучить данные, представленные в тесте, чтобы понять какие данные надо собирать из внешних источников\n* Сформировать желаемый вид датасета, к которому будем стремиться преобразовать собранные данные\n\n### Посмотрим какие данные в тестовой выборке"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(DIR_TEST+'test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим кол-во строк и столбцов тестового датасета проекта\n\nprint('Тестовый датасет проекта содержит {} строк, {} столбцов\\n'.format(test.shape[0], test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подсчитаем количество столбцов по типам данных\nprint(test.dtypes.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим кол-во столбцов, содержащих пустые значения\nprint(f'В {test.isnull().any().sum()} столбцах есть отсутствующие значения.\\n')\n\n# Посмотрим абс и относит величину пропущенных значений по каждому признаку\ncols_isnan=pd.DataFrame({'count': test.isnull().sum(),\n                              'ratio': test.isnull().sum()/len(test)}).query('count > 0')\nprint('Признаки, в которых есть данные с пропущенными значениями\\n\\n{}'\n      .format(cols_isnan))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def param_data(data): # посмотрим на данные\n  param = pd.DataFrame({\n              'dtypes': data.dtypes.values,\n              'nunique': data.nunique().values,\n              'isna': data.isna().sum().values,\n              'loc[0]': data.loc[0].values,\n              'loc[1]': data.loc[1].values,\n              }, \n             index = data.loc[0].index)\n  return param","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#pd.concat([param_data(asd_99), param_data(a)], axis=1, sort=False)\nparam_data(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переименуем столбцы. \n# Для столбцов, названия которых на английском, все приведем к единому стилю - строчные англ. буквы, \n# разделитель между словами - знак подчеркивания.\n# Несколько столбцов имеют названия на русском. Можно сделаь транслитерацию, но так как их немного, то просто переименуем.\ndef upper_letter(word):\n    for i in range(len(word)):\n        if word[i].isupper() and i!=0:\n            word = word[:i] + ' ' + word[i:].lower()\n    return word.replace(' ', '_').lower()\n\ntest = pd.read_csv(DIR_TEST+'test.csv')\n\ntest.rename(columns=lambda x: upper_letter(x) if re.search('[a-z]', x) else x, inplace=True)\n\nrussian_cols = {'Владельцы': 'owners', 'Владение': 'own', 'ПТС': 'pts', 'Привод': 'drive', \n                'Руль': 'rudder', 'Состояние': 'condition', 'Таможня': 'customs'}\n\ntest.rename(columns=russian_cols, inplace=True)\n\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Распределим признаки по категориям: бинарные, категориальные и числовые\ntest_cols = test.columns#[1:-2]\ntest_binary_cols, test_category_cols, test_numeric_cols = [], [], []\n\nfor j in test_cols:\n    if len(test[j].value_counts(dropna=False))==2:\n        test_binary_cols.append(j)\n    #elif len(test[j].value_counts(dropna=False))<11 or test[j].dtypes==object:\n    elif test[j].dtypes==object:\n        test_category_cols.append(j)\n    else:\n        test_numeric_cols.append(j)\n            \nprint('binary_columns =', test_binary_cols, \\\n      '\\ncategory_columns =', test_category_cols, '-',len(test_category_cols), \n      '\\nnumeric_columns =', test_numeric_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на данные, которые находятся в столбцах vendor и rudder"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in test_binary_cols:\n    display(test[column].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на данные в категориальных признаках"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in test_category_cols:\n    display(test[column].value_counts(dropna=False))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим, что можно сделать с body_type"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['body_type'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признаки 'body_type', 'brand' и 'color' пока трогать не буду.\nПризнак body_type пока не трогаю. Посмотрю потом, что будет в спарсенных данных.\nВ 'brand' всего 12 основых автомобильных брэндов, это не так много.\nВ 'color' - 16 различных цветов. Можно оставить 10 основных цветов, но это можно сделать потом, посмотрев на данные, которые мы возьмем извне.\n\n### Посмотрим, какие данные содержатся в 'complectation_dict'"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['complectation_dict'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Очень много пустых значений - 28268 (81%). Скорее всего информация о полной комплектации автомобиля. Может и можно было бы вытащить какие-нибудь признаки, но пока это делать не будем, так как слишком много пропущенных данных.\n\n### Посмотрим признак 'description'"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['description'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из признака description (описание) можем получить информацию, продажа идет через дилера или от самого собственника, и о возможности оформления в кредит.\n### Дальше идут признаки 'engine_displacement' - объем двигателя, 'engine_power' - мощность двигателя"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['engine_displacement'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Не знаю, что это за аббревиатура LTR и будет ли встречаться еще какая-либо. Поэтому попробую в отдельном датасете разбить на два отдельных поля и посмотрю, что это."},{"metadata":{"trusted":true},"cell_type":"code","source":"engine_displacement_tmp = test['engine_displacement'].str.split(\" \", expand = True)\nparam_data(engine_displacement_tmp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть одна запись, где объема двигателя нет, только аббревиатрура. Этой записи присвоим значение 0.\nЗатем оставим только значение объема двигателя, без аббревиатуры (она одинаковая для всех записей), и приведем к числовому типу."},{"metadata":{"trusted":true},"cell_type":"code","source":"test['engine_displacement'] = engine_displacement_tmp[0]\ntest.loc[test['engine_displacement'] == '', 'engine_displacement'] = 0\ntest['engine_displacement'] = test['engine_displacement'].astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['engine_power'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В признаке 'engine_power' также есть аббревиатура. Посмотрим, какие варианты аббревиатуры встречаются."},{"metadata":{"trusted":true},"cell_type":"code","source":"engine_power_tmp = test['engine_power'].str.split(\" \", expand = True)\nparam_data(engine_power_tmp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Поступим аналогично с engine_displacement - оставим только значение мощности двигателя, без аббревиатуры (она одинаковая для всех записей), и приведем к числовому типу."},{"metadata":{"trusted":true},"cell_type":"code","source":"test['engine_power'] = engine_power_tmp[0]\ntest['engine_power'] = test['engine_power'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим признак 'equipment_dict'"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['equipment_dict'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Идут какие-то характеристики: круиз-контроль, тонированные стекла, usb, т.е. комплектация автомобиля.\nПропусков 9996 (29%), меньше чем в признаке complectation_dict.\nНашла в одной из работ, ребята вытаскивали данные из этого признака. Воспользуюсь их наработкой."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция, которая сделает полный список всех возможных характеристик в тестовой выборке.\n\ndef get_test_features(equipment):\n    # Создаем пустой список, в который будут добавляться все характеристики\n    all_features = []\n    for data in equipment:\n        # Находим все слова между кавычками\n        features=re.findall(r'\\\"(.+?)\\\"',data)\n        # Добавляем в общий список\n        all_features.extend(features)\n    # Удаляем дубликаты\n    all_features = list(dict.fromkeys(all_features))\n    return all_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_features = get_test_features(test[test.equipment_dict.isna()==False].equipment_dict)\nlen(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test.equipment_dict.isna()==False].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Удаляем лишние записи\n# for bad_feature in ['name','Безопасность','values','Комфорт','Мультимедиа','Обзор','Салон','Защита от угона','Элементы экстерьера']:\n#     test_features.remove(bad_feature)  \n\nprint('Всего уникальных признаков:', len(test_features))\nprint(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заменим значение параметра equipment в тестовой выборке на список характеристик.\ndef get_features_test(equipment): \n    features=re.findall(r'\\\"(.+?)\\\"',equipment)  \n    return features\n\ntest.loc[test.equipment_dict.isna()==False, 'equipment_dict'] = test[test.equipment_dict.isna()==False]['equipment_dict'].apply(lambda x: get_features_test(x))\ntest[test.equipment_dict.isna()==False].sample(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Рассмотрим признак 'fuel_type'"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['fuel_type'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Этот признак содержит тип используемого топлива, оставим как есть.\n\n### Рассмотрим признак model_info"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['model_info'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим признак model_name\ndict_model = dict(test['model_name'].value_counts())\ndict_model\nlen(dict_model)\n#model_name = test.loc[mask>1]['model_name'].value_counts()\n#model_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим признак name\ntest['name'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Думаю, что в конце концов надо удалить признаки model_info, model_name, name, так как они не дают новой информации\n\n### Рассмотрим признак price_currency"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['price_currency'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Во всех записях указана одна валюта - рубли. Признак можно будет удалить.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Следующий признак super_gen"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['super_gen'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Этот признак содержит большую часть признаков, которые были по другим реквизитам. Воспользуемся им для заполнения некоторых пустых значений, может быть.\n\n### Следующий рассматриваемый признак vehicle_configuration"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['vehicle_configuration'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим, какие данные содержатся в vehicle_transmission"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['vehicle_transmission'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"vehicle_transmission - трансмиссия (коробка передач)\n\n\n### Посмотрим, какие данные содержатся в owners и own"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['owners'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак owner показывает нам сколько раз машина переходила из рук в руки. Обычно, если машина поменяла слишком много владельцев, то такая машина стоит дешевле, чем та у которой был всего один владелец."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим значения в виде списка\ntest.owners.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обработка owners: сделаю словарь, \ndict_owners = {'3 или более': 3, '1\\xa0владелец': 1, '2\\xa0владельца': 2}\n\n# заменяю значение признака owners, соответствующее ключу dict_owners значением данного ключа\ntest['owners'] = test['owners'].map(dict_owners)\ntest.owners.value_counts()\n\n# преобразую тип данных к int\ntest['owners'] = test['owners'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Рассмотрим признак own:"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['own'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Думаю, что признак own нам не особо нужен, так как у нас есть информация о годе выпуска автомобиля и количестве владельцев. К тому же слишком много пропусков - 22691, т.е. не заполнено 65% данных."},{"metadata":{"trusted":true},"cell_type":"code","source":"# top_body_type = test['body_type'].value_counts()[:10]\n# test['body_type'] = test.body_type.apply(lambda x: x if x in top_body_type.keys() else 'Другой')\n# test['body_type'].value_counts(dropna=False)\n\nown = test['own'].value_counts().reset_index()\nown[own['own']<=1000].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Рассмотрим признак pts"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['pts'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим, какая информация есть по записи с пропуском в pts\ntest[test['pts'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict(test[test['pts'].isna()]['super_gen'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test['pts'].isna()]['description'].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заполним пропущенное значение самым частовстречающимся\ntest.loc[test['pts'].isna(), 'pts'] = test['pts'].mode()[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test.parsing_unixtime==1603118960]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Рассмотрим признак drive"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['drive'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Рассмотрим два последних категориальных признака: condition и customs"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['condition'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['customs'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признаки condition и customs содержат всего по одному значению. Посмотрим в трейне, если там не будет каких-либо других значений, то признаки можно будет удалить."},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на данные, которые содержатся в числовых признаках"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in test_numeric_cols:\n    display(test[column].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Признак number_ofdoors - скорее категориальный признак, parsing_unixtime - попробуем преобразовать в дату"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем parsing_unixtime в дату\ntest['parsing_date']=pd.to_datetime(test['parsing_unixtime'], unit='s')\ntest['parsing_date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Перераспределим признаки по категориям: категориальные и числовые\ntest_cols = test.columns#[1:-2]\ntest_category_cols, test_numeric_cols = [], []\n\nfor j in test_cols:\n    if len(test[j].value_counts(dropna=False))<11 or test[j].dtypes==object:\n        test_category_cols.append(j)\n    else:\n        test_numeric_cols.append(j)\n            \nprint('category_columns =', test_category_cols, '-',len(test_category_cols), \n      '\\nnumeric_columns =', test_numeric_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на распределение числовых данных:\nfig, axes = plt.subplots(nrows=2, ncols=(round(len(test_numeric_cols)/2)+1), figsize=(12, 8))\ni = 0\n\nfor j in test_numeric_cols:\n    plot = sns.distplot(test[j], kde=False, ax=axes.flatten()[i])\n    plot.set_title(j)\n    plot.set_xticklabels([])\n    plt.tight_layout()\n    i = i + 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Прологарифмируем и построим графики распределения логарифмированных переменных."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для начала создам функцию по созданию нового признака:\n\n\ndef creating_new_columns(df, column, function):\n    if function == 'log':\n        df[df[column].name+'_log'] = np.log(df[column][df[column] > 0])\n        df[df[column].name+'_log'].fillna(0, inplace=True)\n    elif function=='sqrt':\n        df[df[column].name+'_sqrt'] = np.sqrt(df[column][df[column] > 0])\n        df[df[column].name+'_sqrt'].fillna(0, inplace=True)\n    elif function =='isNAN':\n        if df[column].isnull().any() == True:\n            df[df[column].name+'_isNAN'] = pd.isna(df[column]).astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для каждого числового признака создам новый признак, содержащий логарифмированную величину этой переменной\n\ntest_numeric_log, func = [], 'log'\n\nfor i in test_numeric_cols:\n    creating_new_columns(test, i, func)\n    test_numeric_log.append(i+'_'+func)\n    \ntest[test_numeric_cols+test_numeric_log].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим распределение логарифмов\nfig, axes = plt.subplots(nrows=2, ncols=(round(len(test_numeric_log)/2)+1), figsize=(12, 8))\ni = 0\n\nfor j in test_numeric_log:\n    plot = sns.distplot(test[j], kde=False, ax=axes.flatten()[i])\n    plot.set_title(j)\n    plot.set_xticklabels([])\n    plt.tight_layout()\n    i = i + 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Построим боксплоты для числовых переменных\nfig, axes = plt.subplots(nrows=1, ncols=len(test_numeric_cols), figsize=(17, 6))\ni = 0\n\nfor j in test_numeric_cols:\n    sns.boxplot(y=test[j], showmeans=True, ax=axes.flatten()[i]);#x=test[\"default\"],\n    plt.tight_layout()#plt.show()\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Выясняем, как ведется нумерация продавцов в зависимости от дня обращения\nsns.scatterplot(x='sell_id',y='parsing_unixtime',data=test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Построим боксплоты для логарифмированных переменных\nfig, axes = plt.subplots(nrows=1, ncols=len(test_numeric_log), figsize=(17, 6))\ni = 0\n\nfor j in test_numeric_log:\n    sns.boxplot( y=test[j], showmeans=True, ax=axes.flatten()[i]);#x=df[\"default\"], \n    plt.tight_layout()#plt.show()\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-10-26T12:46:49.007668Z","iopub.status.busy":"2020-10-26T12:46:49.006762Z","iopub.status.idle":"2020-10-26T12:47:02.121152Z","shell.execute_reply":"2020-10-26T12:47:02.120434Z"},"papermill":{"duration":13.16556,"end_time":"2020-10-26T12:47:02.12133","exception":false,"start_time":"2020-10-26T12:46:48.95577","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train = pd.read_csv(DIR_TRAIN+'all_auto_ru__24_12_2020.csv', sep=';') # датасет для обучения модели\n#test = pd.read_csv(DIR_TEST+'test.csv')\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим кол-во строк и столбцов обучающего датасета проекта\nprint('Обучающий датасет проекта содержит {} строк, {} столбцов\\n'.format(train.shape[0], train.shape[1]))\n\n# Подсчитаем количество столбцов по типам данных\nprint(train.dtypes.value_counts())\n\n# Определим кол-во столбцов, содержащих пустые значения\nprint(f'В {train.isnull().any().sum()} столбцах есть отсутствующие значения.\\n')\n\n# Посмотрим абс и относит величину пропущенных значений по каждому признаку\ncols_isnan=pd.DataFrame({'count': train.isnull().sum(),\n                              'ratio': train.isnull().sum()/len(train)}).query('count > 0')\nprint('Признаки, в которых есть данные с пропущенными значениями\\n\\n{}'\n      .format(cols_isnan))\n\n#pd.concat([param_data(train), param_data(test)], axis=1, sort=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удалю строки с пропусками в признаке price обучающей выборки\ntrain.dropna(subset=['price'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим кол-во столбцов, содержащих пустые значения\nprint(f'В {train.isnull().any().sum()} столбцах есть отсутствующие значения.\\n')\n\n# Посмотрим абс и относит величину пропущенных значений по каждому признаку\ncols_isnan=pd.DataFrame({'count': train.isnull().sum(),\n                              'ratio': train.isnull().sum()/len(train)}).query('count > 0')\nprint('Признаки, в которых есть данные с пропущенными значениями\\n\\n{}'\n      .format(cols_isnan))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_data(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Распределим признаки обучающего датасета по категориям: бинарные, категориальные и числовые\ntrain_cols = train.columns#[:-2]\ntrain_binary_cols, train_category_cols, train_numeric_cols = [], [], []\n\nfor j in train_cols:\n    if len(train[j].value_counts(dropna=False))==2:\n        train_binary_cols.append(j)\n    elif len(train[j].value_counts(dropna=False))<11 or train[j].dtypes==object:\n    #elif test[j].dtypes==object:\n        train_category_cols.append(j)\n    else:\n        train_numeric_cols.append(j)\n            \nprint('binary_columns =', train_binary_cols, '\\ncategory_columns =', train_category_cols, '-',len(train_category_cols), \n      '\\nnumeric_columns =', train_numeric_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравним данные в train и test\nfor column in binary_cols:\n    display(test[column].value_counts())\n    \nfor column in train_binary_cols:\n    display(train[column].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.vendor.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.vehicle_transmission.value_counts())\nprint(test.vehicle_transmission.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.drive.value_counts())\nprint(test.drive.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заменим русские значения на английские в признаке \n# rudder, pts, fuel_type, vehicle_transmission и drive тестовой выборки\ndict_rudder = {'Левый': 'LEFT',\n               'Правый': 'RIGHT'}\n\ndict_pts = {'Оригинал': 'ORIGINAL', \n            'Дубликат': 'DUPLICATE'}\n\ndict_test_fuel = {'бензин': 'GASOLINE', \n                  'гибрид': 'HYBRID', \n                  'дизель': 'DIESEL',\n                  'электро': 'ELECTRO',\n                  'газ': 'LPG'}\n\ndict_transmission = {'автоматическая': 'AUTOMATIC',\n                     'механическая': 'MECHANICAL',\n                     'роботизированная': 'ROBOT',\n                     'вариатор': 'VARIATOR'}\n\ndict_drive = {'передний': 'FORWARD_CONTROL',\n              'задний': 'REAR_DRIVE',\n              'полный': 'ALL_WHEEL_DRIVE'}\n\n\ntest['rudder'] = test['rudder'].map(dict_rudder)\ntest['pts'] = test['pts'].map(dict_pts)\ntest['fuel_type'] = test['fuel_type'].map(dict_test_fuel)\ntest['vehicle_transmission'] = test['vehicle_transmission'].map(dict_transmission)\ntest['drive'] = test['drive'].map(dict_drive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train['body_type'].value_counts())\ndisplay(test['body_type'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Переведем все символы в нижний регистр и на всякий случай, если есть удалим пробелы в конце и начале.\ntrain['body_type'] = train['body_type'].apply(lambda x: x.strip().lower())\ndisplay(train['body_type'].value_counts())\nprint(train.body_type.nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Позаимствовала из работы одного из студентов обработку body_type (Группа DST-17 Владимир Юшманов)\n\ntrain['bodytype'] = [str(x).lower().replace('.', '') for x in train['body_type']]\ntest['bodytype'] = [str(x).lower() for x in test['body_type']]\n\n# Заменим длинные типы в train'е на обобщенные значения\nbody_type_list = list(train['bodytype'].unique())\ndef get_perf_type(x, body_type_list):\n    for t in body_type_list:\n        if t in x:\n            return t\n        else: continue\n    else: return '0'\n    \ntrain['bodytype'] = train['bodytype'].apply(lambda x: get_perf_type(x, body_type_list))\ntest['bodytype'] = test['bodytype'].apply(lambda x: get_perf_type(x, body_type_list))\n\n# Удалим 7 предложений, для которых не нашлось соответствия типа кузова\ntrain = train[train['bodytype']!='0']\ntrain['body_type'] = train['bodytype']\ntest['body_type'] = test['bodytype']\n\ntrain.drop(columns=['bodytype'], inplace=True)\ntest.drop(columns=['bodytype'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.body_type.unique())\nprint(train.body_type.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Из той же работы обработка color (Группа DST-17 Владимир Юшманов):\ndict_color = {'040001':'чёрный', 'EE1D19':'красный', '0000CC':'синий', \n              'CACECB':'серебристый', '007F00':'зелёный', 'FAFBFB':'белый', \n              '97948F':'серый', '22A0F8':'голубой', '660099':'пурпурный', \n              '200204':'коричневый', 'C49648':'бежевый', 'DEA522':'золотистый', \n              '4A2197':'фиолетовый', 'FFD600':'жёлтый', 'FF8649':'оранжевый', \n              'FFC0CB':'розовый'}\ntrain['color'] = train['color'].map(dict_color)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['color'].value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"При парсинге обратила внимание, что есть признак summary, содержащий данные, которые могут пригодиться.\nДля начала посмотрю, какие данные есть в этом признаке"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['summary']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В summary есть информация об объеме и мощности двигателя, типе кузова, типе привода и используемом топливе.\nДанные о типе кузова, типе привода и используемом топливе уже преобразовала в train к виду, соответствующему тестовой выборке. \nПосмотрю, что содержится в engine_displacement, engine_power обучающей выборки."},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['engine_displacement', 'engine_power']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В engine_displacement обучающей выборки данные представлены по-другому, чем в тестовой, поэтому в обучающей выборке engine_displacement заменю данными из summary."},{"metadata":{"trusted":true},"cell_type":"code","source":"#  В отдельном датасете разделю данные summary на отдельные поля\nsummary_tmp = train['summary'].str.replace(',', '').str.split(\" \", expand = True)\nsummary_tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определим кол-во столбцов, содержащих пустые значения\nprint(f'В {summary_tmp.isnull().any().sum()} столбцах есть отсутствующие значения.\\n')\n\n# Посмотрим абс и относит величину пропущенных значений по каждому признаку\ncols_isnan=pd.DataFrame({'count': summary_tmp.isnull().sum(),\n                              'ratio': summary_tmp.isnull().sum()/len(summary_tmp)}).query('count > 0')\nprint('Признаки, в которых есть данные с пропущенными значениями\\n\\n{}'\n      .format(cols_isnan))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удалю столбцы с 5 по 8\nsummary_tmp.drop([5,6,7,8], axis=1, inplace=True)\n\n# Очищу столбец с данными объема двигателя от лишних символов\nsummary_tmp[0] = summary_tmp[0].str.replace('[A-Z,a-z]', '').str.strip()\nsummary_tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрю список уникальных значений\nsummary_tmp[0].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_tmp.loc[summary_tmp[0] == '']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Есть пустые значения. \nОставлю в summary_tmp только столбец с объемом двигателя и присоединю к train. \nЗаменю данные объема двигателя в обучающей выборке. \nУдалю строки, которые содержат пустые значения объема двигателя.\nУдалю лишний столбец."},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_tmp = summary_tmp[0]\ntrain = pd.concat([train,summary_tmp], axis=1)\n\ntrain['engine_displacement'] = train[0]\ntrain = train.loc[train['engine_displacement'] != '']\ntrain['engine_displacement'] = train['engine_displacement'].astype(float)\ntrain.drop([0], axis=1, inplace=True)\ntrain['engine_displacement']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Посмотрим на данные в признаке owners\ntrain.owners.value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обработка owners: \n\n# Заполню пропущенное значение в признаке pts обучающей выборки значением 0\ntrain['owners'].fillna(0, inplace=True)\n\n# Сделаю словарь\ndict_train_owners = {'4.0': 4, '3.0': 3, '2.0': 2, '1.0': 1, '0.0': 0}\n\n# заменяю значение признака owners, соответствующее ключу dict_owners значением данного ключа\ntrain['owners'] = train['owners'].astype('string').map(dict_train_owners)\n\n# преобразую тип данных к int\ntrain['owners'] = train['owners'].astype(int)#apply(lambda x: round(x))#.\nprint(train.owners.value_counts())\nprint(train.owners.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.number_ofdoors.value_counts(dropna=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заполним пропущенное значение в признаке pts обучающей выборки самым частовстречающимся значением\ntrain.loc[train['pts'].isna(), 'pts'] = train['pts'].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Перераспределим признаки обучающего датасета по категориям: категориальные и числовые\ntrain_cols = train.columns#[:-2]\ntrain_category_cols, train_numeric_cols = [], []\n\nfor j in train_cols:\n    if train[j].dtypes!=object:\n        train_numeric_cols.append(j)\n    else:\n        train_category_cols.append(j)\n            \nprint('category_columns =', train_category_cols, '-',len(train_category_cols), \n      '\\nnumeric_columns =', train_numeric_cols)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Посмотрим корреляцию признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_numeric_cols = ['engine_displacement', 'engine_power', 'mileage', 'model_date', \n                      'number_ofdoors', 'production_date', 'owners']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = pd.concat([train[train_numeric_cols], train.price], axis=1).corr()\ncmap = sns.diverging_palette(5, 250, as_cmap=True)\n\ndef magnify():\n    return [dict(selector=\"th\",\n                 props=[(\"font-size\", \"10pt\")]),\n            dict(selector=\"td\",\n                 props=[('padding', \"0em 0em\")]),\n            dict(selector=\"th:hover\",\n                 props=[(\"font-size\", \"10pt\")]),\n            dict(selector=\"tr:hover td:hover\",\n                 props=[('max-width', '200px'),\n                        ('font-size', '10pt')])\n]\n\ncorr_matrix.style.background_gradient(cmap, axis=1)\\\n    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n    .set_caption(\"Hover to magify\")\\\n    .set_precision(2)\\\n    .set_table_styles(magnify())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Ранг матрицы - {}, det(corr_mat) = {}'.format(np.linalg.matrix_rank(corr_matrix), np.linalg.det(corr_matrix)))\ncorr_matrix.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ранг матрицы корреляций максимальный, но значение определителя матрицы очень близко к нулю. \n\nСамая сильная связь цены с мощностью двигателя и объемом двигателя. Также видно, что между мощностью двигателя и объемом двигателя очень высокий коэффициент корреляции  0.87. "},{"metadata":{},"cell_type":"markdown","source":"### Оценка значимости числовых переменных.\n#### Для оценки значимости числовых переменных будем использовать функцию f_classif из библиотеки sklearn.\nВозможности модуля sklearn.feature_selection могут быть использованы не только для выбора важных признаков, но и для уменьшения размерности, улучшения предсказательной силы моделей, либо для повышения их производительности на очень многомерных наборах данных.\n\nВ основе метода оценки значимости переменных лежит однофакторный дисперсионный анализ (ANOVA). Основу процедуры составляет обобщение результатов двух выборочных t-тестов для независимых выборок (2-sample t).\n\nВ качестве меры значимости мы будем использовать значение f-статистики. Чем значение статистики выше, тем меньше вероятность того, что средние значения не отличаются, и тем важнее данный признак для нашей линейной модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сделаю оценку значимости\nimp_num = pd.Series(f_classif(train[train_numeric_cols], train['price'])[0], index = train_numeric_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Из визуализации распределения важности признаков и видно, что мощность двигателя (engine_power) самый значимый показатель по ANOVA F test, потом количество год выпуска модели (model_date) и в конце идентификатор продавца (sell_id)"},{"metadata":{},"cell_type":"markdown","source":"### Посмотрим на значимость категориальных переменных \n#### Для оценки значимости категориальных переменных будем использовать функцию mutual_info_classif из библиотеки sklearn. Данная функция опирается на непараметрические методы, основанные на оценке энтропии в группах категориальных переменных."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для начала преобразуем данные: \n\n# Для категориальных признаков применим метод кодирования One-Hot Encoding:\n#X_cat = OneHotEncoder(sparse=False).fit_transform(train[train_category_cols].values)\n\n# Для mutual_info_classif не получилось проверить значимость после OneHotEncoder. \n# Прочитала, что можно использовать label_encoder\n\nlabel_encoder = LabelEncoder()\n\ntrain_cat = train.copy()\n\nfor column in train_category_cols:\n    train_cat[column] = label_encoder.fit_transform(train[column])\n    \n# убедимся в преобразовании    \ntrain_cat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imp_cat = pd.Series(mutual_info_classif(train_cat[train_category_cols], train['price'],#  \n                                     discrete_features=True), index = train_category_cols)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Таким образом, самым значимым признаком по Mutual information тесту является описание (description) и конфигурация транспортного средства (vehicle_configuration), потом идет полное описание (super_gen) и в конце валюта (price_currency)."},{"metadata":{},"cell_type":"markdown","source":"## Подготовка данных к машинному обучению"},{"metadata":{},"cell_type":"markdown","source":"### Теперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sys\nimport re\nfrom datetime import datetime\n\nfrom sklearn.feature_selection import f_classif, mutual_info_classif\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tqdm.notebook import tqdm\nfrom catboost import CatBoostRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor, BaggingRegressor, ExtraTreesClassifier, GradientBoostingClassifier\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.tree import ExtraTreeRegressor\nfrom sklearn.cluster import KMeans\nfrom sklearn.base import clone\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import auc, roc_auc_score, roc_curve\nfrom sklearn.model_selection import cross_validate\n\npd.options.mode.chained_assignment = None\npd.set_option('display.max_columns', None)\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt\n\n# зафиксируем RANDOM_SEED, чтобы эксперименты были воспроизводимы!\nRANDOM_SEED = 42\n\n# CATBOOST\nITERATIONS = 5000\nLR         = 0.1\n\n# Объявим функции:\ndef param_data(data): # посмотрим на данные\n  param = pd.DataFrame({\n              'dtypes': data.dtypes.values,\n              'nunique': data.nunique().values,\n              'isna': data.isna().sum().values,\n              'loc[0]': data.loc[0].values,\n              'loc[1]': data.loc[1].values,\n              }, \n             index = data.loc[0].index)\n  return param\n\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))\n\n\n# Функция переименования столбцов \n\ndef upper_letter(word):\n    for i in range(len(word)):\n        if word[i].isupper() and i!=0:\n            word = word[:i] + ' ' + word[i:].lower()\n    return word.replace(' ', '_').lower()\n\n# Функция от Владимира Юшманова\ndef get_perf_type(x, body_type_list):\n    for t in body_type_list:\n        if t in x:\n            return t\n        else: continue\n    else: return '0'\n\n# Функция от Vandr, которая сделает полный список всех возможных характеристик в тестовой выборке\n\ndef get_test_features(equipment):\n    # Создаем пустой список, в который будут добавляться все характеристики\n    all_features = []\n    for data in equipment:\n        # Находим все слова между кавычками\n        features=re.findall(r'\\\"(.+?)\\\"',data)\n        # Добавляем в общий список\n        all_features.extend(features)\n    # Удаляем дубликаты\n    all_features = list(dict.fromkeys(all_features))\n    return all_features\n\n\n# Функция замены значения параметра equipment в тестовой выборке на список характеристик от Vandr \n\ndef get_features_test(equipment): \n    features=re.findall(r'\\\"(.+?)\\\"',equipment)  \n    return features\n\n\n# Функция по созданию нового признака:\n\ndef creating_new_columns(df, column, function):\n    if function == 'log':\n        df[df[column].name+'_log'] = np.log(df[column][df[column] > 0])\n        df[df[column].name+'_log'].fillna(0, inplace=True)\n    elif function=='sqrt':\n        df[df[column].name+'_sqrt'] = np.sqrt(df[column][df[column] > 0])\n        df[df[column].name+'_sqrt'].fillna(0, inplace=True)\n    elif function =='isNAN':\n        if df[column].isnull().any() == True:\n            df[df[column].name+'_isNAN'] = pd.isna(df[column]).astype('uint8')\n            \n\n# Создадим необходимые словари\n\n# Словарь для color\ndict_color = {'040001':'чёрный', 'EE1D19':'красный', '0000CC':'синий', \n              'CACECB':'серебристый', '007F00':'зелёный', 'FAFBFB':'белый', \n              '97948F':'серый', '22A0F8':'голубой', '660099':'пурпурный', \n              '200204':'коричневый', 'C49648':'бежевый', 'DEA522':'золотистый', \n              '4A2197':'фиолетовый', 'FFD600':'жёлтый', 'FF8649':'оранжевый', \n              'FFC0CB':'розовый'}\n\n# Словарь для owners обучающей выборки\ndict_train_owners = {'4.0': 4, '3.0': 3, '2.0': 2, '1.0': 1, '0.0': 0}\n\n# Словари для замены русских значений на английские в признаках \n# rudder, pts, fuel_type, vehicle_transmission и drive тестовой выборки\ndict_rudder = {'Левый': 'LEFT',\n               'Правый': 'RIGHT'}\n\ndict_pts = {'Оригинал': 'ORIGINAL', \n            'Дубликат': 'DUPLICATE'}\n\ndict_test_fuel = {'бензин': 'GASOLINE', \n                  'гибрид': 'HYBRID', \n                  'дизель': 'DIESEL',\n                  'электро': 'ELECTRO',\n                  'газ': 'LPG'}\n\ndict_transmission = {'автоматическая': 'AUTOMATIC',\n                     'механическая': 'MECHANICAL',\n                     'роботизированная': 'ROBOT',\n                     'вариатор': 'VARIATOR'}\n\ndict_drive = {'передний': 'FORWARD_CONTROL',\n              'задний': 'REAR_DRIVE',\n              'полный': 'ALL_WHEEL_DRIVE'}\n\n# Словарь owners для тестовой выборки \ndict_owners = {'3 или более': 3, '1\\xa0владелец': 1, '2\\xa0владельца': 2}","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# на всякий случай, заново подгружаем данные\nVERSION    = 15\nDIR_TRAIN  = '/kaggle/input/parsingautoru24122020/' # подключила к ноутбуку внешний датасет\nDIR_TEST   = '../input/sf-dst-car-price-prediction/'\nVAL_SIZE   = 0.20   # 20%\n\n!ls '../input'\n\n# Загружаем train\ntrain = pd.read_csv(DIR_TRAIN+'all_auto_ru__24_12_2020.csv', sep=';') # датасет для обучения модели\nsample_submission = pd.read_csv(DIR_TEST+'sample_submission.csv')\n\n# Загружаем test\ntest = pd.read_csv(DIR_TEST+'test.csv')\n\n# Переименовываем столбцы тестовой выборки\ntest.rename(columns=lambda x: upper_letter(x) if re.search('[a-z]', x) else x, inplace=True)\n\nrussian_cols = {'Владельцы': 'owners', 'Владение': 'own', 'ПТС': 'pts', 'Привод': 'drive', \n                'Руль': 'rudder', 'Состояние': 'condition', 'Таможня': 'customs'}\n\ntest.rename(columns=russian_cols, inplace=True)\n#____________________________________\nengine_displacement_tmp = test['engine_displacement'].str.split(\" \", expand = True)\ntest['engine_displacement'] = engine_displacement_tmp[0]\ntest.loc[test['engine_displacement'] == '', 'engine_displacement'] = 0\n\n#____________________________________\nsummary_tmp = train['summary'].str.replace(',', '').str.split(\" \", expand = True)\nsummary_tmp[0] = summary_tmp[0].str.replace('[A-Z,a-z]', '').str.strip()\nsummary_tmp = summary_tmp[0]\ntrain = pd.concat([train,summary_tmp], axis=1)\ntrain['engine_displacement'] = train[0]\ntrain = train.loc[train['engine_displacement'] != '']","execution_count":89,"outputs":[{"output_type":"stream","text":"parsing-all-moscow-auto-ru-09-09-2020  sf-dst-car-price-prediction\r\nparsingautoru24122020\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproc_data(df_input):\n    '''includes several functions to pre-process the predictor data.'''\n    \n    df_output = df_input.copy()\n    \n    # ################### 1. Предобработка #################################################\n    \n    # Обработка body_type \n    # возьму данные из test\n    test['bodytype'] = [str(x).lower().replace('.', '') for x in test['body_type']]\n    # Сделаю список типов кузовов\n    body_type_list = list(test['bodytype'].unique())\n\n    # Заполню пропущенное значение в признаке pts самым частовстречающимся значением\n    df_output.loc[df_output['pts'].isna(), 'pts'] = df_output['pts'].mode()[0]\n\n    if 'price' in df_output.columns:\n        df_output['bodytype'] = [str(x).lower() for x in df_output['body_type']]\n        df_output['brand'] = df_output['brand'].apply(lambda x: x.strip().upper())\n        df_output['color'] = df_output['color'].map(dict_color)\n        df_output.loc[(df_output['fuel_type'] == 'CLA_KLASSE'), 'fuel_type'] = 'GASOLINE'\n        df_output['owners'].fillna(0, inplace=True)\n        df_output['owners'] = df_output['owners'].astype('string').map(dict_train_owners)\n        df_output.description.fillna('Отсутствует', inplace=True)\n        df_output.dropna(subset=['price'], inplace=True)\n        df_output.drop(['mark', 'model', 'summary',0], axis=1, inplace=True)\n    else:\n        df_output['bodytype'] = [str(x).lower().replace('.', '') for x in test['body_type']]\n        df_output['rudder'] = df_output['rudder'].map(dict_rudder)\n        df_output['pts'] = df_output['pts'].map(dict_pts)\n        df_output['fuel_type'] = df_output['fuel_type'].map(dict_test_fuel)\n        df_output['vehicle_transmission'] = df_output['vehicle_transmission'].map(dict_transmission)\n        df_output['drive'] = df_output['drive'].map(dict_drive)\n        #engine_displacement_tmp = df_output['engine_displacement'].str.split(\" \", expand = True)\n        #df_output['engine_displacement'] = engine_displacement_tmp[0]\n        #df_output.loc[test['engine_displacement'] == '', 'engine_displacement'] = 0\n        #df_output['engine_displacement'] = df_output['engine_displacement'].astype(int)\n        engine_power_tmp = df_output['engine_power'].str.split(\" \", expand = True)\n        df_output['engine_power'] = engine_power_tmp[0]\n        df_output['engine_power'] = df_output['engine_power'].astype(int)\n        df_output['owners'] = df_output['owners'].map(dict_owners)\n        \n    # Заменим длинные типы в train'е на обобщенные значения\n    df_output['bodytype'] = df_output['bodytype'].apply(lambda x: get_perf_type(x, body_type_list))\n        \n\n    # Удалим предложения, для которых не нашлось соответствия типа кузова\n    df_output = df_output[df_output['bodytype']!='0']\n    df_output['body_type'] = df_output['bodytype']\n    \n    # Преобразую тип данных к float\n    df_output['engine_displacement'] = df_output['engine_displacement'].astype(float)\n    \n    # преобразую тип данных к int\n    df_output['owners'] = df_output['owners'].astype(int)\n    df_output['number_ofdoors'] = df_output['number_ofdoors'].astype(int)\n\n    # Удалю \"лишние признаки\" \n    df_output.drop(['bodytype', 'car_url', 'complectation_dict', 'equipment_dict', 'image', 'condition', \n                    'customs', 'equipment_dict', 'model_info', 'model_name', 'name', 'own', 'parsing_unixtime',\n                    'price_currency', 'vehicle_configuration', 'super_gen', 'sell_id'], axis=1, inplace=True) # \n\n\n    # Распределю признаки по категориям: категориальные и числовые\n    df_output_cols = df_output.columns#[1:-2]\n    output_category_cols, output_numeric_cols = [], []\n\n    for j in df_output_cols:\n        if j!='price':\n            if df_output[j].dtypes!=object:\n                output_numeric_cols.append(j)\n            else:\n                output_category_cols.append(j)\n            \n    # Для каждого числового признака создам новый признак, содержащий логарифмированную величину этой переменной\n    output_numeric_log, func = [], 'log'\n\n    for i in output_numeric_cols:\n        creating_new_columns(df_output, i, func)\n        output_numeric_log.append(i+'_'+func)\n    \n    # Для каждого числового признака создам новый признак, содержащий корень величины этой переменной\n    output_numeric_sqrt, func = [], 'sqrt'\n\n    for i in output_numeric_cols:\n        creating_new_columns(df_output, i, func)\n        output_numeric_sqrt.append(i+'_'+func)\n\n    #___________________________________________\n\n    # Добавлю к списку числовых признаков логарифмы и квадратичные признаки\n    output_numeric_cols = output_numeric_cols + output_numeric_log + output_numeric_sqrt\n\n            \n    print('category_columns =', output_category_cols, '-',len(output_category_cols), \n          '\\nnumeric_columns =', output_numeric_cols)\n    \n    # Будем запускать отдельно для train и отдельно для test\n    \n    if 'price' in df_output.columns:\n        Y = df_output['price'].values\n        df_output.drop(['price'], axis=1, inplace=True)\n        return df_output, Y, output_category_cols, output_numeric_cols\n    else:\n        return df_output, output_category_cols, output_numeric_cols","execution_count":90,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Построение модели"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Запускаем отдельно для train и для test. Проверяем, что получилось:\ntrain_df, y, category_cols, numeric_cols = preproc_data(train)\ntest_df, category_cols, numeric_cols = preproc_data(test)\nprint(train_df.shape, test_df.shape)","execution_count":91,"outputs":[{"output_type":"stream","text":"category_columns = ['body_type', 'brand', 'color', 'description', 'fuel_type', 'vehicle_transmission', 'vendor', 'pts', 'drive', 'rudder'] - 10 \nnumeric_columns = ['engine_displacement', 'engine_power', 'mileage', 'model_date', 'number_ofdoors', 'production_date', 'owners', 'engine_displacement_log', 'engine_power_log', 'mileage_log', 'model_date_log', 'number_ofdoors_log', 'production_date_log', 'owners_log', 'engine_displacement_sqrt', 'engine_power_sqrt', 'mileage_sqrt', 'model_date_sqrt', 'number_ofdoors_sqrt', 'production_date_sqrt', 'owners_sqrt']\ncategory_columns = ['body_type', 'brand', 'color', 'description', 'fuel_type', 'vehicle_transmission', 'vendor', 'pts', 'drive', 'rudder'] - 10 \nnumeric_columns = ['engine_displacement', 'engine_power', 'mileage', 'model_date', 'number_ofdoors', 'production_date', 'owners', 'engine_displacement_log', 'engine_power_log', 'mileage_log', 'model_date_log', 'number_ofdoors_log', 'production_date_log', 'owners_log', 'engine_displacement_sqrt', 'engine_power_sqrt', 'mileage_sqrt', 'model_date_sqrt', 'number_ofdoors_sqrt', 'production_date_sqrt', 'owners_sqrt']\n(126205, 31) (34686, 31)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def encoding_data(df_input, cat_cols, num_cols):\n    df_output = df_input.copy()\n    # Преобразуем данные: \n    label_encoder = LabelEncoder()\n\n    X_cat = pd.DataFrame()\n\n    for column in cat_cols:\n        X_cat[column] = label_encoder.fit_transform(df_output[column])#X_cat[column].astype('category').cat.codes\n        \n    # Для категориальных признаков применим метод кодирования One-Hot Encoding:\n    #X_cat = OneHotEncoder(sparse = False).fit_transform(df_output[cat_cols].values)\n\n    # Стандартизируем числовые переменные:\n    X_num = StandardScaler().fit_transform(df_output[num_cols].values)\n\n    # Объединим стандартизованные числовые и закодированные категориальные переменные \n    # в одно признаковое пространство\n    df_output = np.hstack([X_num, X_cat])\n    return df_output\n\n    #return df_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = encoding_data(train_df, category_cols, numeric_cols)\ntest_data = encoding_data(test_df, category_cols, numeric_cols)\nprint(train_data.shape, test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model 1: Создадим \"наивную\" модель \nЭта модель будет предсказывать среднюю цену по модели двигателя (engineDisplacement). \nC ней будем сравнивать другие модели.\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"## Train Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"# для baseline просто возьму пару схожих признаков без полной обработки\ncolumns = ['body_type', 'brand', 'production_date', 'engine_displacement', 'mileage']\ndf_train = train_df[columns]\ndf_test = test_df[columns]\n\n\n# Объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n\n\nfor colum in ['body_type', 'brand', 'engine_displacement']:\n    data[colum] = data[colum].astype('category').cat.codes\n\nX = data.query('sample == 1').drop(['sample'], axis=1)\nX_sub = data.query('sample == 0').drop(['sample'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train = X_train.copy()\ntmp_train['price'] = y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp_train.groupby('engine_displacement')['price'].median()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Находим median по экземплярам engineDisplacement в трейне и размечаем тест\npredict = X_test['engine_displacement'].map(tmp_train.groupby('engine_displacement')['price'].median())\n\n#оцениваем точность\nprint(f\"Точность наивной модели по метрике MAPE: {(mape(y_test, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.037164,"end_time":"2020-10-26T12:47:03.997616","exception":false,"start_time":"2020-10-26T12:47:03.960452","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# # Model 2 : CatBoost\n![](https://pbs.twimg.com/media/DP-jUCyXcAArRTo.png:large)   \n\n\nУ нас в данных практически все признаки категориальные. Специально для работы с такими данными была создана очень удобная библиотека CatBoost от Яндекса. [https://catboost.ai](http://)     \nНа данный момент **CatBoost является одной из лучших библиотек для табличных данных!**\n\n#### Полезные видео о CatBoost (на русском):\n* [Доклад про CatBoost](https://youtu.be/9ZrfErvm97M)\n* [Свежий Туториал от команды CatBoost (практическая часть)](https://youtu.be/wQt4kgAOgV0) "},{"metadata":{"papermill":{"duration":0.035833,"end_time":"2020-10-26T12:47:04.149539","exception":false,"start_time":"2020-10-26T12:47:04.113706","status":"completed"},"tags":[]},"cell_type":"markdown","source":"## Простая модель с тремя признаками"},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:47:04.256865Z","iopub.status.busy":"2020-10-26T12:47:04.248328Z","iopub.status.idle":"2020-10-26T12:48:12.17834Z","shell.execute_reply":"2020-10-26T12:48:12.17762Z"},"papermill":{"duration":67.991521,"end_time":"2020-10-26T12:48:12.178488","exception":false,"start_time":"2020-10-26T12:47:04.186967","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = LR,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE']\n                         )\nmodel.fit(X_train, y_train,\n         #cat_features=cat_features_ids,\n         eval_set=(X_test, y_test),\n         verbose_eval=100,\n         use_best_model=True,\n         plot=True\n         )","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-10-26T12:48:12.389716Z","iopub.status.busy":"2020-10-26T12:48:12.388722Z","iopub.status.idle":"2020-10-26T12:48:12.393213Z","shell.execute_reply":"2020-10-26T12:48:12.392387Z"},"papermill":{"duration":0.135345,"end_time":"2020-10-26T12:48:12.393406","exception":false,"start_time":"2020-10-26T12:48:12.258061","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model.save_model('catboost_single_model_like_baseline.model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict(X_test)\n\n# оцениваем точность\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.088891,"end_time":"2020-10-26T12:48:12.562943","exception":false,"start_time":"2020-10-26T12:48:12.474052","status":"completed"},"tags":[]},"cell_type":"markdown","source":"Вот так просто со старта, даже не трогая сами данные и не подбирая настройки catboosta, получаем модель с уровнем ошибки в 9.18%!"},{"metadata":{},"cell_type":"markdown","source":"## Построение модели на всех признаках\n---\n### Разбиваем датасет на тренировочный и тестовый"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df\nX_sub = test_df\n\n# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\n# проверяем\ntest_df.shape, train_df.shape, X.shape, X_train.shape, X_test.shape\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обучаем модель, генерируем результат и сравниваем с тестом\n### Первая модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(iterations = 50,\n                          cat_features=category_cols,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          silent=True,\n                         )\nmodel.fit(X_train, y_train,\n         eval_set=(X_test, y_test),\n         use_best_model=True,\n         verbose=False,\n         plot=True\n         )\n\nmodel.save_model('catboost_model.model')\n\npredict = model.predict(X_test)\n# оцениваем точность\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, predict))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{},"cell_type":"markdown","source":"Курс доллара изменился с сентября (данные тестовой выборки) по декабрь (данные обучающей выборки) на 3.25%. \nПоэтому в сабмит сделаю поправку на изменение курса доллара."},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission_cat = np.round(model.predict(X_sub)*0.9685)\nsample_submission['price'] = predict_submission_cat.astype(int)\nsample_submission.to_csv('submission_model_1.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"С этой моделью на лидеборде score стало 42.94"},{"metadata":{},"cell_type":"markdown","source":"## Вторая модель. Подбор параметров.\n\nПопробую логарифмировать price"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подготовим данные. \n\ncopy_train = train_df.copy()\ncopy_test = test_df.copy()\n\n# Объединяем трейн и тест в один датасет\ncopy_train['sample'] = 1 # помечаем где у нас трейн\ncopy_test['sample'] = 0 # помечаем где у нас тест\n\ncopy_data = copy_test.append(copy_train, sort=False).reset_index(drop=True) # объединяем\n\nfor column in category_cols:\n    copy_data[column] = copy_data[column].astype('category').cat.codes\n    \nX = copy_data.query('sample == 1').drop(['sample'], axis=1)\nX_sub = copy_data.query('sample == 0').drop(['sample'], axis=1)\n\n# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\n# проверяем\ntest_df.shape, X_sub.shape, X.shape, X_train.shape, X_test.shape\n","execution_count":92,"outputs":[{"output_type":"execute_result","execution_count":92,"data":{"text/plain":"((34686, 31), (34686, 31), (126205, 31), (100964, 31), (25241, 31))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = CatBoostRegressor(iterations = 50,\n                          cat_features=category_cols,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          silent=True,\n                         )\ngrid = {'learning_rate': [ 0.13, 0.14, 0.15]\n        ,'depth': [12]\n        ,'l2_leaf_reg': [7, 7.5, 8]\n        ,'random_strength': [0.3]}\n\nmodel_cb = CatBoostRegressor(iterations = 5000,\n                       random_seed = RANDOM_SEED,\n                       eval_metric='MAPE',\n                       custom_metric=['R2', 'MAE'],\n                       silent=True,\n                       learning_rate=0.13, depth=12,\n                       l2_leaf_reg=8, random_strength=0.3)\n\nmodel_cb.fit(X_train, np.log(y_train),\n         eval_set=(X_test, np.log(y_test)),\n         verbose=False,\n         use_best_model=True,\n         plot=True)\n\nmodel_cb.save_model('catboost_log_model.model')\n\npredict_exp = np.round(np.exp(model_cb.predict(X_test)))\n# оцениваем точность\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_exp))*100:0.2f}%\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_log_submission = np.round(np.exp(model_cb.predict(X_sub))*0.9685)\nsample_submission['price'] = predict_log_submission.astype(int)\nsample_submission.to_csv('submission_model_2.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"На лидеборде score стало 28.16.\n\nПосле корректировки цены с поправкой на изменение курса доллара со времени тестовой выборки, score на ЛБ стало 27.94\nПосле удаления признаков price_currency и parsing_unixtime score стало 22.03"},{"metadata":{},"cell_type":"markdown","source":"## Кросс-валидация (CV)\n\nКогда мы делаем отбор признаков или перебираем настройки модели, мы постоянно смотрим в тестовые данные (X_test), что может привести к подгону под тестовые данные. В итоге мы получим Переобучение (overfitting).\nЧтобы избежать этого, можно сразу использовать кросс-валидацию по фолдам.\n\nНиже представлен Пример, как можно организовать обучение модели на 5 фолдах, с дальнейшим объединением предсказаний от каждой модели."},{"metadata":{"trusted":true},"cell_type":"code","source":"def cat_model(y_train, X_train, X_test, y_test):\n    model = CatBoostRegressor(iterations = ITERATIONS,\n                              learning_rate = LR,\n                              eval_metric='MAPE',\n                              random_seed = RANDOM_SEED,)\n    model.fit(X_train, y_train,\n              cat_features=cat_features_ids,\n              eval_set=(X_test, y_test),\n              verbose=False,\n              use_best_model=True,\n              plot=False)\n    \n    return(model)\n\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N_FOLDS    = 5\n\n# CATBOOST\nITERATIONS = 2000\nLR         = 0.1\n\nidx = np.argsort(model_cb.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features_ids = np.where(X_train.dtypes == object)[0].tolist()\n\nsubmissions = pd.DataFrame(0,columns=[\"sub_1\"], index=sample_submission.index) # куда пишем предикты по каждой модели\nscore_ls = []\nsplits = list(KFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_SEED).split(X, y))\n\nfor idx, (train_idx, test_idx) in tqdm(enumerate(splits), total=N_FOLDS,):\n    # use the indexes to extract the folds in the train and validation data\n    X_train, y_train, X_test, y_test = X.iloc[train_idx], y[train_idx], X.iloc[test_idx], y[test_idx]\n    # model for this fold\n    model = cat_model(y_train, X_train, X_test, y_test,)\n    # score model on test\n    test_predict = model.predict(X_test)\n    test_score = mape(y_test, test_predict)\n    score_ls.append(test_score)\n    print(f\"{idx+1} Fold Test MAPE: {mape(y_test, test_predict):0.3f}\")\n    # submissions\n    submissions[f'sub_{idx+1}'] = model.predict(X_sub)\n    model.save_model(f'catboost_fold_{idx+1}.model')\n    \nprint(f'Mean Score: {np.mean(score_ls):0.3f}')\nprint(f'Std Score: {np.std(score_ls):0.4f}')\nprint(f'Max Score: {np.max(score_ls):0.3f}')\nprint(f'Min Score: {np.min(score_ls):0.3f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submissions blend"},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submissions['blend'] = (submissions.sum(axis=1)/len(submissions.columns))*0.9685\nsample_submission['price'] = np.round(submissions['blend'].values)\nsample_submission.to_csv('submission_blend_2.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Результат ухудшился, score на лидеборде стал 42.54"},{"metadata":{},"cell_type":"markdown","source":"## Random Forrest"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrandom_grid = {'n_estimators': [int(x) for x in np.linspace(start = 100, stop = 400, num = 4)],\n               'max_features': ['auto', 'sqrt'],\n               'max_depth': [int(x) for x in np.linspace(5, 15, num = 6)] + [None],\n               'min_samples_split': [2, 5, 10],\n               'min_samples_leaf': [1, 2, 4],\n               'bootstrap': [True, False]}\n\nrfr = RandomForestRegressor(random_state = RANDOM_SEED)\n\nrf_random = RandomizedSearchCV(estimator = rfr, \n                               param_distributions = random_grid, \n                               n_iter = 100, \n                               cv = 3, \n                               verbose=10, \n                               random_state=RANDOM_SEED, \n                               n_jobs = -1)\nrf_random.fit(X_train, np.log(y_train))\nprint(rf_random.best_params_)\n\n#best_params_: \n#{'n_estimators': 300,\n# 'min_samples_split': 10,\n# 'min_samples_leaf': 1,\n# 'max_features': 'sqrt',\n# 'max_depth': None,\n# 'bootstrap': False}\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#best_rfr = rf_random.best_estimator_\nbest_rfr = RandomForestRegressor(random_state=RANDOM_SEED\n                      , n_estimators=300\n                      , min_samples_split=10\n                      , min_samples_leaf=1\n                      , max_features='sqrt'\n                      , max_depth=None\n                      , bootstrap=False)\n\nbest_rfr.fit(X_train, np.log(y_train))\n\n\npredict_rfr = np.exp(best_rfr.predict(X_test))\nprint(y_test, predict_rfr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_rfr))*100:0.2f}%\")\npredict_rfr_submission = np.round(np.exp(best_rfr.predict(X_sub))*0.9685)\nsample_submission['price'] = predict_rfr_submission.astype(int)\nsample_submission.to_csv('submission_model_rfr.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"В результате score на ЛБ 19.05"},{"metadata":{},"cell_type":"markdown","source":"# Stacking\n## Как каждая модель относится к категориальным переменным?\nCatBoost обладает гибкостью, позволяя задавать индексы категориальных столбцов, чтобы его можно было кодировать как кодирование в одно касание с использованием one_hot_max_size (используйте кодирование в одно касание для всех функций с числом различных значений, меньшим или равным данному значению параметра).\n\nЕсли вы ничего не передаете в аргументе cat_features, CatBoost будет обрабатывать все столбцы как числовые переменные.\n\nПримечание. Если в cat_features не указан столбец со строковыми значениями, CatBoost выдает ошибку. Кроме того, столбец с типом int по умолчанию будет считаться числовым по умолчанию, его необходимо указать в cat_features, чтобы алгоритм воспринимал его как категориальный.\n\n\nКак и в CatBoost, LightGBM также может обрабатывать категориальные функции, вводя имена функций. Он не конвертируется в одноразовое кодирование и намного быстрее, чем одноразовое кодирование. LGBM использует специальный алгоритм, чтобы найти значение разделения категориальных признаков.\n\nПримечание. Перед построением набора данных для LGBM вы должны преобразовать свои категориальные функции в тип int. Он не принимает строковые значения, даже если вы передаете его через параметр categoryorical_feature.\n\n\nВ отличие от CatBoost или LGBM, XGBoost не может обрабатывать категориальные функции сам по себе, он принимает только числовые значения, подобные случайному лесу. Поэтому перед подачей категориальных данных в XGBoost необходимо выполнить различные кодировки, такие как кодирование меток, среднее кодирование или однократное кодирование.\n\n\nRandomForestRegressor, LinearRegression - им тоже нужны на вход данные без категориальных признаков\n\n## Подготовка\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Снова объединю копии обучающей и тестовой выборок\ncopy_data = copy_test.append(copy_train, sort=False).reset_index(drop=True) # объединяем\n\ncopy_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сделаю теперь dummies-преобразование \nfor column in category_cols:\n    dummies = pd.get_dummies(copy_data[column], prefix = copy_data[column].name)\n\n    # Удаляем исходный столбец и добавляем dummies\n    copy_data = copy_data.drop(copy_data[column].name, axis=1).join(dummies)\n\ncopy_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dummies-преобразование сделать не получилось (выходит ошибка переполнения памяти). Поэтому оставлю датасеты как есть."},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in category_cols:\n    copy_data[column] = copy_data[column].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь разделяем обучающую и тестовую выборки\n\nX = copy_data.query('sample == 1').drop(['sample'], axis=1)\nX_sub = copy_data.query('sample == 0').drop(['sample'], axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=VAL_SIZE, shuffle=True, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_meta_feature(model, X_train, X_test, y_train, cv):\n   \n    X_meta_train = np.zeros_like(y_train, dtype = np.float32)\n    for train_fold_index, predict_fold_index in cv.split(X_train):\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n        \n        folded_model = clone(model)\n        folded_model.fit(X_fold_train, y_fold_train)\n        X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n        \n    meta_model = clone(model)\n    meta_model.fit(X_train, y_train)\n    \n    X_meta_test = meta_model.predict_proba(X_test)[:,1]\n    \n    return X_meta_train, X_meta_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=N_FOLDS, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 - Catboost\n\ncat_features_ids = np.where(X.dtypes == object)[0].tolist()\n\nX_meta_train_features = []\nX_meta_test_features = []\n\nmodel = CatBoostRegressor(iterations = ITERATIONS,\n                          learning_rate = LR,\n                          random_seed = RANDOM_SEED,\n                          eval_metric='MAPE',\n                          custom_metric=['R2', 'MAE'],\n                          loss_function = 'RMSE'\n                         )\n\nX_meta_train = np.zeros_like(y, dtype = np.float32)\nX_meta_test = np.zeros(len(X_sub), dtype = np.float32)\nfor train_fold_index, predict_fold_index in cv.split(X):\n    X_fold_train, X_fold_predict = X.iloc[train_fold_index], X.iloc[predict_fold_index]\n    y_fold_train = y[train_fold_index]\n\n    folded_model = clone(model)\n    folded_model.fit(X_fold_train, y_fold_train,\n                     cat_features=cat_features_ids,\n                     eval_set=(X_test, y_test),\n                     verbose_eval=1000,\n                     use_best_model=True,\n                     plot=False\n)\n    X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n    X_meta_test += folded_model.predict(X_sub)\n\nX_meta_test = X_meta_test / N_FOLDS\n\nX_meta_train_features.append(X_meta_train)\nX_meta_test_features.append(X_meta_test)\n\nprint(model.get_best_score())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 - RandomForestRegressor\n\nmodel = RandomForestRegressor(n_estimators=400, \n                              random_state=42, \n                              min_samples_split=10, \n                              min_samples_leaf=1, \n                              max_features='sqrt')\n\nX_meta_train = np.zeros_like(y, dtype = np.float32)\nX_train_num = X\nX_sub_num = X_sub\n\nfor train_fold_index, predict_fold_index in cv.split(X_train_num):\n    X_fold_train, X_fold_predict = X_train_num.iloc[train_fold_index], X_train_num.iloc[predict_fold_index]\n    y_fold_train = y[train_fold_index]\n\n    folded_model = clone(model)\n    folded_model.fit(X_fold_train, y_fold_train)\n    X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n\nmeta_model = clone(model)\nmeta_model.fit(X_train_num, y)\n\nX_meta_test = meta_model.predict(X_sub_num)\n\nX_meta_train_features.append(X_meta_train)\nX_meta_test_features.append(X_meta_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_meta_test_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3 LinearRegression\n\nmodel = LinearRegression(normalize = True)\n\nX_meta_train = np.zeros_like(y, dtype = np.float32)\n\nfor train_fold_index, predict_fold_index in cv.split(X_train_num):\n    X_fold_train, X_fold_predict = X_train_num.iloc[train_fold_index], X_train_num.iloc[predict_fold_index]\n    y_fold_train = y[train_fold_index]\n\n    folded_model = clone(model)\n    folded_model.fit(X_fold_train, y_fold_train)\n    X_meta_train[predict_fold_index] = folded_model.predict(X_fold_predict)\n\nmeta_model = clone(model)\nmeta_model.fit(X_train_num, y)\n\nX_meta_test = meta_model.predict(X_sub_num)\n\nX_meta_train_features.append(X_meta_train)\nX_meta_test_features.append(X_meta_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked_features_train = np.vstack(X_meta_train_features[:2]).T\nstacked_features_test = np.vstack(X_meta_test_features[:2]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### В качестве финальной модели используем линейную регрессию."},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = LinearRegression()\nfinal_model.fit(stacked_features_train, y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['price'] = np.floor(final_model.predict(stacked_features_test)*0.9685 / 10000) * 10000 \nsample_submission.to_csv('submission_stack_model_1.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\nfrom collections import defaultdict\nfrom sklearn.model_selection import KFold\n\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true))\n\ndef print_regression_metrics(y_true, y_pred):\n    mse = mean_squared_error(y_true, y_pred)\n    rmse = np.sqrt(mse)\n    r2 = r2_score(y_true, y_pred)\n    mae = mean_absolute_error(y_true, y_pred)\n    mape = mean_absolute_percentage_error(y_true, y_pred)\n    print(f'RMSE = {rmse:.2f}, MAE = {mae:.2f}, R-sq = {r2:.2f}, MAPE = {mape:.2f} ')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_meta_feature(clf, X_train, X_test, y_train, cv):\n    \"\"\"\n    Computes meta-features usinf the classifier cls\n    \n    :arg model: scikit-learn classifier\n    :arg X_train, y_train: training set\n    :arg X_test: testing set\n    :arg cv: cross-validation folding\n    \"\"\"\n    \n    X_meta_train = np.zeros_like(y_train, dtype = np.float32)\n    X_meta_test = np.zeros(len(X_test), dtype=np.float32)\n    for train_fold_index, predict_fold_index in cv.split(X_train):\n        X_fold_train, X_fold_predict = X_train[train_fold_index], X_train[predict_fold_index]\n        y_fold_train = y_train[train_fold_index]\n        \n        folded_clf = clone(clf)\n        folded_clf.fit(X_fold_train, y_fold_train)\n            \n        \n        X_meta_train[predict_fold_index] = folded_clf.predict(X_fold_predict)\n        \n        print_regression_metrics(X_meta_train[predict_fold_index], y_train[predict_fold_index])\n        X_meta_test += folded_clf.predict(X_test)\n    \n    n = cv.n_splits\n    X_meta_test = X_meta_test / n\n    \n    return X_meta_train, X_meta_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_meta_features(regressors, X_train, X_test, y_train, cv):\n   \n    features = [\n        compute_meta_feature(clf, X_train, X_test, y_train, cv)\n        for clf in tqdm(regressors)\n    ]\n    \n    stacked_features_train = np.stack([\n        features_train for features_train, features_test in features\n    ], axis=-1)\n\n    stacked_features_test = np.stack([\n        features_test for features_train, features_test in features\n    ], axis=-1)\n    \n    return stacked_features_train, stacked_features_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n\ndef compute_metric(clf, X_train=X_train, y_train=y_train, X_test=X_test):\n    clf.fit(X_train, y_train)\n    y_test_pred = clf.predict(X_test)\n    return print_regression_metrics(y_test, y_test_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.base import clone\n\nfrom sklearn.preprocessing import StandardScaler\n# Стандартизируем данные:\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\ntest = scaler.fit_transform(X_sub)\n\nstacked_features_train, stacked_features_test = generate_meta_features([\n    RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED),\n    BaggingRegressor(ExtraTreesRegressor(n_estimators=100, random_state=RANDOM_SEED)),\n    CatBoostRegressor(loss_function = 'MAE',\n                         eval_metric = 'MAPE',\n                         learning_rate=0.005,\n                         iterations=4500,\n                         l2_leaf_reg=2,\n                         depth=6,\n                         bootstrap_type = 'Bayesian',\n                         random_seed=42,\n                         od_type='Iter',\n                         od_wait=100)\n    ], X_train, test, y_train, cv)\n\n\n#Строим мета-алгоритм\n\nfinal_model = LinearRegression()\nfinal_model.fit(stacked_features_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = np.round((final_model.predict(stacked_features_test)/1000))*1000\n\nsample_submission['price'] =  np.round(y_pred*0.9685)\nsample_submission.to_csv('submission_stack_model_2.csv', index=False)\n\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model 3"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Подготовим данные. \n\n# Снова объединяем копии трейн и тест в один датасет\ncopy_data = copy_test.append(copy_train, sort=False).reset_index(drop=True) # объединяем\n\nfor column in category_cols:\n    copy_data[column] = copy_data[column].astype('category').cat.codes\n    \nX = copy_data.query('sample == 1').drop(['sample'], axis=1)\nX_sub = copy_data.query('sample == 0').drop(['sample'], axis=1)\n\n# Прологарифмируем целевой признак\ny = np.log(y)\n\n# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n\n# Запоминаем порядок колонок\ncolumn_list = test_df.columns\n\n# Устанавливаем порядок колонок как для тестовой выборки, иначе предсказания неверные.\nX_train = X_train[column_list]\nX_test = X_test[column_list]\nX_sub =X_sub[column_list]\n#y = np.log(train_data.price.values)\n\n# проверяем\ntest_df.shape, X_sub.shape, X.shape, X_train.shape, y_train.shape[0], X_test.shape, y_test.shape[0]\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\nfrom vecstack import stacking\n\nfrom sklearn.linear_model import LinearRegression \nfrom sklearn.ensemble import ExtraTreesRegressor    \nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\n\n\ndef mape(y_true, y_pred):\n    return np.mean(np.abs((y_pred-y_true)/y_true))\n\n\n# Configure models\nRANDOM_SEED = 42\n\n\nlr = LinearRegression(normalize=True, n_jobs=-1)\n\netc = ExtraTreesRegressor(n_estimators=500,  n_jobs=-1,\n                          random_state=RANDOM_SEED)  # max_depth=5,\ncatb = CatBoostRegressor(iterations=3500,\n                                 learning_rate=0.05,\n                                 random_seed=RANDOM_SEED,\n                                 eval_metric='MAPE',\n                                 verbose = 500\n                                 )\nrf = RandomForestRegressor(random_state=RANDOM_SEED, n_jobs=-1,\n                           n_estimators=500)  # , max_depth=3\n\nknn = KNeighborsRegressor(n_neighbors=5, \n                          weights='uniform', \n                          algorithm='auto', \n                          leaf_size=30, \n                          p=2, metric='minkowski', n_jobs=-1)\n\n\nprint(\"Finished setting up regressors at \", dt.datetime.now())\n\n# Initialize 1-st level models.\nmodels = [catb, rf, etc, knn]\n\n# Compute stacking features\nS_train, S_test = stacking(models, X_train, y_train, X_test,\n                           regression=True, metric=mape, n_folds=4,\n                           shuffle=True, random_state=RANDOM_SEED, verbose=2)\n\n# Initialize 2-nd level model\nmodel = lr\n\n# Fit 2-nd level model\nmodel = model.fit(S_train, y_train)\n\n# Predict\ny_test_pred = np.exp(model.predict(X_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['price'] = np.round(np.exp(model.predict(X_sub)))\n# sample_submission['price'] = sample_submission['price'].apply(lambda x: round(x/1000)*1000)\nsample_submission.to_csv('submission_stack_model_3.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Результат"},{"metadata":{"papermill":{"duration":0.083769,"end_time":"2020-10-26T12:48:13.930562","exception":false,"start_time":"2020-10-26T12:48:13.846793","status":"completed"},"tags":[]},"cell_type":"markdown","source":"В итоге получили **MAPE 30%** на ЛБ!\n\nБольшая разница в ошибке может указывать на то что тест и трейн имеют различия по выборке или то что данные в трейне могли уже устареть и их нужно обновлять."},{"metadata":{},"cell_type":"markdown","source":"## GradientBoostingRegressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"gb = GradientBoostingRegressor(min_samples_split=2, learning_rate=0.03, max_depth=10, n_estimators=1000)\ngb.fit(X_train, np.log(y_train))\n\npredict_gb_test = np.exp(gb.predict(X_test))\npredict_gb_submission = np.exp(gb.predict(X_sub))\n\nprint(f\"Точность модели по метрике MAPE: {(mape(y_test, predict_gb_test))*100:0.2f}%\")","execution_count":93,"outputs":[{"output_type":"stream","text":"Точность модели по метрике MAPE test: 5.12%\nТочность модели по метрике MAPE submission: 5.12%\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['price'] = np.round(np.exp(gb.predict(X_sub))*0.9685) #predict_gb_submission\nsample_submission.to_csv('submission_gb_model.csv', index=False)\nsample_submission.head(10)","execution_count":96,"outputs":[{"output_type":"execute_result","execution_count":96,"data":{"text/plain":"      sell_id      price\n0  1100575026   640054.0\n1  1100549428   807559.0\n2  1100658222   839820.0\n3  1100937408   770743.0\n4  1101037972   845295.0\n5  1100912634   744943.0\n6  1101228730   627963.0\n7  1100165896   422903.0\n8  1100768262  1863357.0\n9  1101218501   811704.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sell_id</th>\n      <th>price</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1100575026</td>\n      <td>640054.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1100549428</td>\n      <td>807559.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1100658222</td>\n      <td>839820.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1100937408</td>\n      <td>770743.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1101037972</td>\n      <td>845295.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1100912634</td>\n      <td>744943.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1101228730</td>\n      <td>627963.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1100165896</td>\n      <td>422903.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1100768262</td>\n      <td>1863357.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1101218501</td>\n      <td>811704.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Результат\n\n#### На ЛБ результат стал 17.94"},{"metadata":{"papermill":{"duration":0.087712,"end_time":"2020-10-26T12:48:14.104388","exception":false,"start_time":"2020-10-26T12:48:14.016676","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# What's next?\nИли что еще можно сделать, чтоб улучшить результат:\n\n* Спарсить свежие данные \n* Посмотреть, что можно извлечь из признаков или как еще можно обработать признаки\n* Сгенерировать новые признаки\n* Попробовать подобрать параметры модели\n* Попробовать другие алгоритмы и библиотеки ML\n* Сделать Ансамбль моделей, Blending, Stacking"},{"metadata":{},"cell_type":"markdown","source":"Подробный чек лист: https://docs.google.com/spreadsheets/d/1I_ErM3U0Cs7Rs1obyZbIEGtVn-H47pHNCi4xdDgUmXY/edit?usp=sharing"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}